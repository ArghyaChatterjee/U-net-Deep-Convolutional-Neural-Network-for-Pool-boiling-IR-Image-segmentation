{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from skimage.morphology import label\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "import random\n",
    "from u_net import Unet, get_unet_256\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_df(train_path, test_path, mask_path, img_size):\n",
    "    train_ids = next(os.walk(train_path))[2]\n",
    "    test_ids = next(os.walk(test_path))[2]\n",
    "    X_train = np.zeros((len(train_ids), img_size, img_size, 3), dtype=np.uint8)\n",
    "    Y_train = np.zeros((len(train_ids), img_size, img_size, 1), dtype=np.bool)\n",
    "    for i, id_ in enumerate(train_ids):\n",
    "        path = train_path + '/' + id_\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        X_train[i] = img\n",
    "\n",
    "        m_path = mask_path + '/' + id_\n",
    "        msk = io.imread(m_path, plugin='pil')\n",
    "        # msk = cv2.imread(m_path, 0)\n",
    "        msk = cv2.resize(msk, (img_size, img_size))\n",
    "        msk = msk[..., np.newaxis]\n",
    "        #msk = np.expand_dims(msk,axis = -1)\n",
    "        Y_train[i] = msk\n",
    "\n",
    "    X_test = np.zeros((len(test_ids), img_size, img_size, 3), dtype=np.uint8)\n",
    "    # sizes_test = []\n",
    "    for i, id_ in enumerate(test_ids):\n",
    "        path = test_path + '/' + id_\n",
    "        imgTest = cv2.imread(path)\n",
    "        imgTest = cv2.resize(imgTest, (img_size, img_size))\n",
    "        X_test[i] = imgTest\n",
    "\n",
    "    return X_train, Y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(xtr, xval, ytr, yval, batch_size):\n",
    "    data_gen_args = dict(horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         rotation_range=90.,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         zoom_range=0.2,\n",
    "                         fill_mode = \"constant\",\n",
    "                         cval = 0.)\n",
    "\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    image_datagen.fit(xtr, seed=7)\n",
    "    mask_datagen.fit(ytr, seed=7)\n",
    "    image_generator = image_datagen.flow(xtr, batch_size=batch_size, seed=7)\n",
    "    mask_generator = mask_datagen.flow(ytr, batch_size=batch_size, seed=7)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "    val_gen_args = dict()\n",
    "    image_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "    mask_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "    image_datagen_val.fit(xval, seed=7)\n",
    "    mask_datagen_val.fit(yval, seed=7)\n",
    "    image_generator_val = image_datagen.flow(xval, batch_size=batch_size, seed=7)\n",
    "    mask_generator_val = mask_datagen.flow(yval, batch_size=batch_size, seed=7)\n",
    "    val_generator = zip(image_generator_val, mask_generator_val)\n",
    "\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Running_file\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded!\n"
     ]
    }
   ],
   "source": [
    "def pred():\n",
    "    preds_test = model.predict(X_test, verbose=1)\n",
    "    preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "    preds_test_upsampled = []\n",
    "    for i in range(len(preds_test)):\n",
    "        preds_test_upsampled.append(cv2.resize(preds_test[i],\n",
    "                                               (sizes_test[i][0], sizes_test[i][1])).transpose(1, 0))\n",
    "\n",
    "    test_ids = next(os.walk(test_path))[1]\n",
    "    new_test_ids = []\n",
    "    rles = []\n",
    "    for n, id_ in enumerate(test_ids):\n",
    "        rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "        rles.extend(rle)\n",
    "        new_test_ids.extend([id_] * len(rle))\n",
    "    sub = pd.DataFrame()\n",
    "    sub['ImageId'] = new_test_ids\n",
    "    sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "    sub.to_csv('sub_aug_512.csv', index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    img_size = 256\n",
    "    batch_size =4\n",
    "    train_path = 'Input/train'\n",
    "    test_path = 'Input/test'\n",
    "    mask_path = 'Input/mask'\n",
    "\n",
    "    X_train, Y_train, X_test = make_df(train_path, test_path, mask_path, img_size)\n",
    "    xtr, xval, ytr, yval = train_test_split(X_train, Y_train, test_size=0.1, random_state=7)\n",
    "    train_generator, val_generator = generator(xtr, xval, ytr, yval, batch_size)\n",
    "\n",
    "    #model = Unet(img_size)\n",
    "    model = get_unet_256(input_shape=(img_size, img_size, 3),num_classes=1)\n",
    "    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[mean_iou, dice_coeff])\n",
    "    callbacks = [EarlyStopping(monitor='val_mean_iou',\n",
    "                               patience=50,\n",
    "                               verbose=2,\n",
    "                               min_delta=1e-4,\n",
    "                               mode='max'\n",
    "                                ),\n",
    "                 ReduceLROnPlateau(monitor='val_mean_iou',\n",
    "                                   factor=np.sqrt(0.1),\n",
    "                                   patience=5,\n",
    "                                   cooldown=2,\n",
    "                                   verbose=1,\n",
    "                                   epsilon=1e-4,\n",
    "                                   mode='max'\n",
    "                                    ),\n",
    "                 ModelCheckpoint(monitor='val_mean_iou',\n",
    "                                 filepath='weights/unet_256_arghya.{epoch:02d}-{val_loss:.5f}-{val_mean_iou:.5f}.h5',\n",
    "                                 save_best_only=True,\n",
    "                                 save_weights_only=False,\n",
    "                                 mode='max',\n",
    "                                 #period = 1\n",
    "                                  ),\n",
    "                 TensorBoard(log_dir=\"logs/\",  histogram_freq=0,  write_graph=True, write_images=True)]\n",
    "\n",
    "    model.load_weights('weights/unet_256_arghya.272-0.03398-0.96499.h5')\n",
    "    print('weights loaded!')\n",
    "    \n",
    "    preds_test = model.predict(X_test)\n",
    "    preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "    ix = range(0, 6)\n",
    "    d= 1\n",
    "    for item in ix:\n",
    "        imgTest = X_test[item]\n",
    "        mask_in = (preds_test_t[item]).astype(np.uint8)\n",
    "        mask_cleaned = (mask_in * 255).astype(np.uint8)\n",
    "        mask_cleaned = np.squeeze(mask_cleaned)\n",
    "        mask_color = cv2.cvtColor(mask_cleaned, cv2.COLOR_GRAY2BGR)\n",
    "        img_masked = cv2.addWeighted(imgTest, 0.5, mask_color, 0.5, 0)\n",
    "        filename = \"heat_1100_kwm2_8bit_%3.5d.tif\" %d\n",
    "        cv2.imwrite(filename, mask_color)\n",
    "        d+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
